{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOY0Fjap23Tr2B8yB6mJfHq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### 最小二乗法と射影行列 (Projection Matrix)\n","\n","射影行列は、ベクトルを特定の空間に射影するための行列であり、最小二乗法の計算において重要な役割を果たします。\n","\n","---\n","\n","これらの性質は、行列計算の基礎となり、多くの応用問題において役立ちます。特に、行列式やトレースの特性を理解することは、線形代数の深い理解に繋がります。\n","\n","### 最小二乗法と射影行列 (Projection Matrix)\n","\n","- 最小二乗問題の設定：\n","  \n","  ベクトル $\\mathbf{b}$ を空間 $\\text{span}(\\mathbf{A})$ 上に射影することで、誤差ベクトルの長さを最小化します。\n","$ (\\mathbf{b} - \\mathbf{A}\\hat{\\mathbf{x}})^T \\mathbf{A} = 0 $\n","\n","  これにより、ベクトル $\\mathbf{b} - \\mathbf{A}\\hat{\\mathbf{x}}$ と $\\mathbf{A}$ の各列ベクトルが直交します。\n","\n","- 正規方程式 (Normal Equation)：\n","$ \\mathbf{A}^T \\mathbf{A} \\hat{\\mathbf{x}} = \\mathbf{A}^T \\mathbf{b} $\n","\n","  これにより、解 $\\hat{\\mathbf{x}}$ が得られます：\n","$ \\hat{\\mathbf{x}} = (\\mathbf{A}^T \\mathbf{A})^{-1} \\mathbf{A}^T \\mathbf{b} $\n","\n","- 射影行列 (Projection Matrix) の導出：\n","$ \\mathbf{A}\\hat{\\mathbf{x}} = \\mathbf{A}(\\mathbf{A}^T \\mathbf{A})^{-1} \\mathbf{A}^T \\mathbf{b} $\n","\n","  これは、$\\mathbf{b}$ を空間 $\\text{span}(\\mathbf{A})$ に射影する行列です。\n","\n","---\n","\n","### 行列の性質と解の安定性\n","\n","- **射影行列の性質**：\n","  \n","  射影行列はベクトル $\\mathbf{b}$ を行列 $\\mathbf{A}$ の列空間に射影します。もし $\\mathbf{b}$ が列空間に含まれていれば、最小二乗解はその射影ベクトルとなります。\n","\n","- **フルカラムランク (Full Column Rank)** の場合：\n","  \n","  行列 $\\mathbf{A}$ がフルカラムランクの場合、射影行列 $(\\mathbf{A}^T\\mathbf{A})^{-1}\\mathbf{A}^T$ が存在し、解が安定します。フルカラムランクでない場合、擬似逆行列 (Pseudo-inverse) を使用します。\n","\n","---\n","\n","### 測定値とノイズ\n","\n","- 測定された値 $\\mathbf{z}$ が次のように与えられる場合：\n","$ \\mathbf{z} = \\mathbf{A}\\mathbf{x} + \\mathbf{n} $\n","\n","  ここで、$\\mathbf{n}$ はノイズ成分です。このとき、最小二乗法を用いて $\\mathbf{x}$ を推定することが目標となります。\n","\n","---\n","\n","これらの概念は、最小二乗法や回帰分析において非常に重要です。特に、射影行列は、与えられたデータを最も適した形で表現するための手法として広く用いられています。\n"],"metadata":{"id":"uhJnejb2raBn"}},{"cell_type":"markdown","source":["##最小二乗法 (Least Square Method)\n","\n","最適なパラメータを求める方法として、データに対する誤差を最小化する\n","\n","\n","傾きと切片の1次関数\n","\n","\n","$$\n","L = \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2\n","$$\n","\n","\n","解法2\n","\n","\n","$$\n","\\|\\mathbf{y} - \\mathbf{w}\\mathbf{X}\\|^2 \\text{行列に対して偏微分}\n","$$\n","\n","$$\n","\\frac{\\partial L}{\\partial \\mathbf{w}} = -\\mathbf{X}^T (\\mathbf{y} - \\mathbf{w}\\mathbf{X}) = 0\n","$$\n","\n","$$\n","\\mathbf{w} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}\n","$$\n","\n","$$\n","\\mathbf{y} =\n","\\begin{pmatrix}\n","y_1 \\\\\n","y_2 \\\\\n","\\vdots \\\\\n","y_N\n","\\end{pmatrix}, \\quad\n","\\mathbf{X} =\n","\\begin{pmatrix}\n","1 & x_{11} & \\cdots & x_{1D} \\\\\n","1 & x_{21} & \\cdots & x_{2D} \\\\\n","\\vdots & \\vdots & \\ddots & \\vdots \\\\\n","1 & x_{N1} & \\cdots & x_{ND}\n","\\end{pmatrix}, \\quad\n","\\mathbf{w} =\n","\\begin{pmatrix}\n","w_0 \\\\\n","w_1 \\\\\n","w_2 \\\\\n","\\vdots \\\\\n","w_D\n","\\end{pmatrix}\n","$$\n","\n","\n","※完全な解を求めることができる\n","\n"],"metadata":{"id":"aIj1PsU_YAIc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pqoorEUUrZhE"},"outputs":[],"source":[]}]}